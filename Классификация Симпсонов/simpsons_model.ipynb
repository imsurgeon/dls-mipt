{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simpsons-model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imsurgeon/dls-mipt/blob/master/%D0%9A%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F%20%D0%A1%D0%B8%D0%BC%D0%BF%D1%81%D0%BE%D0%BD%D0%BE%D0%B2/simpsons_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiCyXXB-FrID"
      },
      "source": [
        "Екатерина Апраксина\n",
        "160077195"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09eLXffLF6Yn"
      },
      "source": [
        "Kaggle score: 0.97874"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZzXpgvIzbAY"
      },
      "source": [
        "Импорты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN_wLfjozbAY"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import natsort\n",
        "from PIL import Image\n",
        "import copy\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDHAxJTvzbAY"
      },
      "source": [
        "GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrrOxZ5OzbAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa42e0d-25b7-4b03-e5a9-a1bd5972a566"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda:0\"\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"Using CPU\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-7xbhHIzbAY"
      },
      "source": [
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark =  True \n",
        "torch.backends.cudnn.deterministic = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy0uLRyNzbAY"
      },
      "source": [
        "**Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsSJ4nSczbAY"
      },
      "source": [
        "Преобразования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAA1y2wEzbAY"
      },
      "source": [
        "imshow = lambda x: plt.imshow(x.permute(1,2,0))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25UHBTA_zbAY"
      },
      "source": [
        "transforms_dict = {\n",
        "    'eval': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
        "    ]),\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomResizedCrop(224, scale=(0.8, 1), ratio=(0.75, 1.333333), interpolation=2),\n",
        "        torchvision.transforms.RandomPerspective(distortion_scale=0.3, p=0.9, interpolation=3, fill=0),\n",
        "        torchvision.transforms.RandomAffine(degrees=30, shear=20, resample=False),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzuRq7TMzbAY"
      },
      "source": [
        "Загрузка датасетов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMpy06el2SYN",
        "outputId": "ffb99f47-66b6-4434-c0b7-0d855f10cc2c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBdM7qfxzbAY"
      },
      "source": [
        "train_path = '/content/gdrive/My Drive/simpsons/data/train/'\n",
        "test_path = '/content/gdrive/My Drive/simpsons/data/test/'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYPQVENdzbAY"
      },
      "source": [
        "data = datasets.ImageFolder(root = train_path, transform = transforms_dict['eval'])\n",
        "data_augmented = datasets.ImageFolder(root = train_path, transform = transforms_dict['train'])\n",
        "\n",
        "n_classes = len(data.classes)\n",
        "\n",
        "label_to_name = {v: k for k, v in data.class_to_idx.items()}\n",
        "\n",
        "train_indices, val_indices, _, _, = train_test_split(np.arange(len(data)), data.targets, test_size = 0.1, stratify=data.targets, random_state = 42)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(torch.utils.data.Subset(data_augmented, train_indices), batch_size = 100)\n",
        "val_dataloader = torch.utils.data.DataLoader(torch.utils.data.Subset(data, val_indices), batch_size = 100)\n",
        "final_train_dataloader = torch.utils.data.DataLoader(data_augmented, batch_size=100, shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLBstE-FzbAY"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D-vX7dqzbAZ"
      },
      "source": [
        "class TestImageFolder(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root, transform, ext = '.jpg'):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        files_unsorted = [i for i in os.listdir(root) if ext in i]\n",
        "        self.files = natsort.natsorted(files_unsorted) \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        paths = os.path.join(self.root, self.files[idx])\n",
        "        image = Image.open(paths).convert(\"RGB\")\n",
        "        tensor_image = self.transform(image)\n",
        "        return tensor_image"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHm8lC2azbAZ"
      },
      "source": [
        "test_data = TestImageFolder(test_path, transforms_dict['eval'], ext='.jpg')\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=100)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtXiWhP7zbAZ"
      },
      "source": [
        "Цикл обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcM4LYIWzbAZ"
      },
      "source": [
        "best_f1 = 0\n",
        "best_model = None"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGbjZnHWzbAZ"
      },
      "source": [
        "def train(model, train_dataloader, val_dataloader, num_epoch, loss_function, optimizer, scheduler, device):\n",
        "\n",
        "    global best_f1\n",
        "    global best_model\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_f1 = []\n",
        "    \n",
        "    train_size = float(len(train_dataloader.dataset))\n",
        "    if val_dataloader is not None:\n",
        "        val_size = float(len(val_dataloader.dataset))\n",
        "    \n",
        "    for i in range(num_epoch):\n",
        "        \n",
        "        print('epoch',i)\n",
        "\n",
        "        train_running_loss = 0\n",
        "        model.train(True)\n",
        "        for j, (inputs, labels) in enumerate(train_dataloader):\n",
        "            \n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        train_losses.append(train_running_loss/train_size)\n",
        "          \n",
        "        if val_dataloader is not None:\n",
        "            val_preds = []\n",
        "            val_true = []\n",
        "            val_running_loss = 0\n",
        "            model.train(False)\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_dataloader:\n",
        "\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "                    loss = loss_function(outputs, labels)\n",
        "\n",
        "                    val_running_loss += loss.item() * inputs.size(0)\n",
        "                    _, batch_preds = torch.max(outputs, axis=1)\n",
        "                    val_preds += batch_preds.tolist()\n",
        "                    val_true += labels.tolist()\n",
        "            \n",
        "            val_losses.append(val_running_loss/val_size)\n",
        "            val_f1.append(f1_score(val_true, val_preds, average='macro'))\n",
        "            \n",
        "            print('Validation loss:', val_losses[-1])\n",
        "            print('Validation f1:', val_f1[-1])\n",
        "        \n",
        "            if val_f1[-1] > best_f1:\n",
        "                best_f1 = val_f1[-1]\n",
        "                best_model = copy.deepcopy(model)       \n",
        "        \n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        \n",
        "    end_time = time.time()\n",
        "    \n",
        "    print('Total time: ',end_time - start_time)\n",
        "    print('Average time per epoch: ',(end_time - start_time) / num_epoch)\n",
        "    \n",
        "    return {'train_losses': train_losses,\n",
        "            'val_losses': val_losses,\n",
        "            'val_f1': val_f1,\n",
        "           }"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcGGAC-KzbAZ"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgCgNAN-zbAZ"
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5AH5OaIzbAZ"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "for param in model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "    \n",
        "model.fc = torch.nn.Linear(num_ftrs, n_classes)\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXHgxZbozbAZ"
      },
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.3)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9zM-gFyzbAZ",
        "outputId": "0a749de8-3d3d-4ba2-9cab-df6f6eaafb65"
      },
      "source": [
        "result_dict_frozen = train(model, final_train_dataloader, None, 5, loss_function, optimizer, scheduler, device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0\n",
            "epoch 1\n",
            "epoch 2\n",
            "epoch 3\n",
            "epoch 4\n",
            "Total time:  18912.821585655212\n",
            "Average time per epoch:  3782.5643171310426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrekVTgFzbAZ"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsW4JV6czbAZ",
        "outputId": "f3250e8d-44b6-4bae-e5b6-5e3d1204e985"
      },
      "source": [
        "result_dict_unfrozen = train(model, final_train_dataloader, None, 5, loss_function, optimizer, scheduler, device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0\n",
            "epoch 1\n",
            "epoch 2\n",
            "epoch 3\n",
            "epoch 4\n",
            "Total time:  19552.374881982803\n",
            "Average time per epoch:  3910.4749763965606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LvAdVzBzbAZ"
      },
      "source": [
        "**Предсказание**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqL4hIe_zbAZ"
      },
      "source": [
        "model = model.to(device)\n",
        "model.train(False)\n",
        "with torch.no_grad():\n",
        "    test_preds = []\n",
        "    for batch in test_dataloader:\n",
        "        batch = batch.to(device)\n",
        "        _, preds = model(batch).max(axis=1)\n",
        "        test_preds.append(preds.tolist())\n",
        "    test_preds = sum(test_preds,[])\n",
        "test_preds = [label_to_name[label] for label in test_preds]\n",
        "submission_df = pd.DataFrame([*zip(test_data.files,test_preds,)]).rename(columns = {0: 'Id', 1: 'Expected'})"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR_k0aSszbAa"
      },
      "source": [
        "submission_df.to_csv('submission.csv',index=False)"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}